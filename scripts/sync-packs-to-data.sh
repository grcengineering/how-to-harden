#!/usr/bin/env bash
# sync-packs-to-data.sh — Extract marked guide excerpt regions from pack files
# into Jekyll _data YAML for guide embedding.
#
# Usage: bash scripts/sync-packs-to-data.sh
# Output: docs/_data/packs/{vendor}.yml for each vendor with pack code
#
# Marker syntax in pack files:
#   # HTH Guide Excerpt: begin <name>
#   ... extractable code ...
#   # HTH Guide Excerpt: end <name>

set -euo pipefail

REPO_ROOT="$(cd "$(dirname "$0")/.." && pwd)"
PACKS_DIR="${REPO_ROOT}/packs"
DATA_DIR="${REPO_ROOT}/docs/_data/packs"
GITHUB_BASE="https://github.com/grcengineering/how-to-harden/blob/main"

# Build YAML in a native-fs temp directory to avoid WSL2/NTFS append race
# conditions (hundreds of >> appends to an NTFS-mounted file can interleave),
# then atomically copy the finished file to the NTFS destination.
TMPDIR_PACKS=$(mktemp -d)
trap 'rm -rf "${TMPDIR_PACKS}"' EXIT

mkdir -p "${DATA_DIR}"

# Normalize section numbers: 1.01 -> 1.1, 1.10 -> 1.10, 5.04 -> 5.4
normalize_section() {
  local raw="$1"
  local major="${raw%%.*}"
  local minor="${raw#*.}"
  # Strip leading zeros from minor: 01->1, 04->4, 10->10
  minor=$(echo "${minor}" | sed 's/^0*//')
  [ -z "${minor}" ] && minor="0"
  echo "${major}.${minor}"
}

# Extract content between HTH Guide Excerpt markers
# Returns extracted content via stdout, with consistent minimum 2-space indent
# to prevent YAML block scalar indentation errors
extract_region() {
  local file="$1"
  local region_name="$2"
  local raw
  raw=$(sed -n "/^[[:space:]]*# HTH Guide Excerpt: begin ${region_name}\$/,/^[[:space:]]*# HTH Guide Excerpt: end ${region_name}\$/{
    /^[[:space:]]*# HTH Guide Excerpt: begin ${region_name}\$/d
    /^[[:space:]]*# HTH Guide Excerpt: end ${region_name}\$/d
    p
  }" "${file}")
  # Ensure all non-empty lines have at least 2-space indent so YAML block
  # scalars don't break from inconsistent indentation in source code.
  # Lines starting with a non-space character get 2 spaces prepended.
  echo "${raw}" | sed '/^[^[:space:]]/s/^/  /'
}

# List all region names in a file
list_regions() {
  local file="$1"
  grep -oP '^\s*# HTH Guide Excerpt: begin \K.*' "${file}" 2>/dev/null || true
}

# Escape content for YAML literal block scalar
# The content goes after "content: |" with 6-space indent
yaml_content() {
  local content="$1"
  if [ -z "${content}" ]; then
    echo '""'
    return
  fi
  echo "|"
  echo "${content}" | sed 's/^/      /'
}

# Detect language from file extension
detect_lang() {
  local file="$1"
  case "${file}" in
    *.tf)   echo "hcl" ;;
    *.sh)   echo "bash" ;;
    *.yml)  echo "yaml" ;;
    *.py)   echo "python" ;;
    *.ps1)  echo "powershell" ;;
    *.sql)  echo "sql" ;;
    *.js)   echo "javascript" ;;
    *.go)   echo "go" ;;
    *)      echo "plaintext" ;;
  esac
}

# Detect pack type from directory
detect_type() {
  local file="$1"
  case "${file}" in
    */terraform/*)  echo "terraform" ;;
    */api/*)        echo "api" ;;
    */cli/*)        echo "cli" ;;
    */sdk/*)        echo "sdk" ;;
    */db/*)         echo "db" ;;
    */siem/sigma/*) echo "sigma" ;;
    */scripts/*)    echo "scripts" ;;
    *)              echo "other" ;;
  esac
}

# Extract section number from filename: hth-okta-1.01-title.ext -> 1.01
extract_raw_section() {
  local filename="$1"
  # Match hth-{vendor}-{section}-{rest}.{ext}
  echo "${filename}" | sed -n 's/^hth-[a-z0-9-]*-\([0-9]*\.[0-9]*\)-.*/\1/p'
}

# Process a single vendor
process_vendor() {
  local vendor="$1"
  local vendor_dir="${PACKS_DIR}/${vendor}"
  local output_file="${DATA_DIR}/${vendor}.yml"
  # Write to native-fs temp file, then copy to NTFS at the end
  local tmp_file="${TMPDIR_PACKS}/${vendor}.yml"

  if [ ! -d "${vendor_dir}" ]; then
    return
  fi

  echo "# AUTO-GENERATED by scripts/sync-packs-to-data.sh — do not edit manually" > "${tmp_file}"
  echo "# Generated: $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> "${tmp_file}"
  echo "" >> "${tmp_file}"

  # Collect all sections that have marked files
  declare -A sections_seen

  # Find all hth-* files with markers across all subdirectories
  local marked_files=()
  while IFS= read -r -d '' file; do
    if grep -q 'HTH Guide Excerpt: begin' "${file}" 2>/dev/null; then
      marked_files+=("${file}")
    fi
  done < <(find "${vendor_dir}" -name "hth-${vendor}-*" -type f -print0 2>/dev/null | sort -z)

  if [ ${#marked_files[@]} -eq 0 ]; then
    echo "# No marked files found for ${vendor}" >> "${tmp_file}"
    return
  fi

  # Group files by normalized section
  declare -A section_terraform
  declare -A section_api
  declare -A section_cli
  declare -A section_sdk
  declare -A section_db
  declare -A section_sigma

  for file in "${marked_files[@]}"; do
    local basename
    basename=$(basename "${file}")
    local raw_section
    raw_section=$(extract_raw_section "${basename}")

    if [ -z "${raw_section}" ]; then
      continue
    fi

    local section
    section=$(normalize_section "${raw_section}")
    local pack_type
    pack_type=$(detect_type "${file}")
    local rel_path="${file#${REPO_ROOT}/}"

    sections_seen["${section}"]=1

    case "${pack_type}" in
      terraform)
        section_terraform["${section}"]="${file}|${rel_path}|${basename}"
        ;;
      api)
        section_api["${section}"]="${file}|${rel_path}|${basename}"
        ;;
      cli)
        section_cli["${section}"]="${file}|${rel_path}|${basename}"
        ;;
      sdk)
        section_sdk["${section}"]="${file}|${rel_path}|${basename}"
        ;;
      db)
        section_db["${section}"]="${file}|${rel_path}|${basename}"
        ;;
      sigma)
        # Sigma can have multiple files per section (-b, -c, etc.)
        if [ -n "${section_sigma[${section}]+x}" ]; then
          section_sigma["${section}"]="${section_sigma[${section}]}"$'\n'"${file}|${rel_path}|${basename}"
        else
          section_sigma["${section}"]="${file}|${rel_path}|${basename}"
        fi
        ;;
    esac
  done

  # Sort sections numerically and output YAML
  local sorted_sections
  sorted_sections=$(for s in "${!sections_seen[@]}"; do echo "$s"; done | sort -t. -k1,1n -k2,2n)

  for section in ${sorted_sections}; do
    echo "\"${section}\":" >> "${tmp_file}"

    # Terraform
    if [ -n "${section_terraform[${section}]+x}" ]; then
      IFS='|' read -r tf_file tf_rel tf_basename <<< "${section_terraform[${section}]}"
      local tf_lang
      tf_lang=$(detect_lang "${tf_basename}")

      echo "  terraform:" >> "${tmp_file}"
      echo "    lang: \"${tf_lang}\"" >> "${tmp_file}"
      echo "    filename: \"${tf_basename}\"" >> "${tmp_file}"
      echo "    source_url: \"${GITHUB_BASE}/${tf_rel}\"" >> "${tmp_file}"
      echo "    excerpts:" >> "${tmp_file}"

      # Extract each named region
      local regions
      regions=$(list_regions "${tf_file}")
      for region in ${regions}; do
        local content
        content=$(extract_region "${tf_file}" "${region}")
        echo "      ${region}:" >> "${tmp_file}"
        echo "        content: |" >> "${tmp_file}"
        echo "${content}" | sed 's/^/          /' >> "${tmp_file}"
      done
    fi

    # API
    if [ -n "${section_api[${section}]+x}" ]; then
      IFS='|' read -r api_file api_rel api_basename <<< "${section_api[${section}]}"
      local api_lang
      api_lang=$(detect_lang "${api_basename}")

      echo "  api:" >> "${tmp_file}"
      echo "    lang: \"${api_lang}\"" >> "${tmp_file}"
      echo "    filename: \"${api_basename}\"" >> "${tmp_file}"
      echo "    source_url: \"${GITHUB_BASE}/${api_rel}\"" >> "${tmp_file}"
      echo "    excerpts:" >> "${tmp_file}"

      local regions
      regions=$(list_regions "${api_file}")
      for region in ${regions}; do
        local content
        content=$(extract_region "${api_file}" "${region}")
        echo "      ${region}:" >> "${tmp_file}"
        echo "        content: |" >> "${tmp_file}"
        echo "${content}" | sed 's/^/          /' >> "${tmp_file}"
      done
    fi

    # CLI
    if [ -n "${section_cli[${section}]+x}" ]; then
      IFS='|' read -r cli_file cli_rel cli_basename <<< "${section_cli[${section}]}"
      local cli_lang
      cli_lang=$(detect_lang "${cli_basename}")

      echo "  cli:" >> "${tmp_file}"
      echo "    lang: \"${cli_lang}\"" >> "${tmp_file}"
      echo "    filename: \"${cli_basename}\"" >> "${tmp_file}"
      echo "    source_url: \"${GITHUB_BASE}/${cli_rel}\"" >> "${tmp_file}"
      echo "    excerpts:" >> "${tmp_file}"

      local regions
      regions=$(list_regions "${cli_file}")
      for region in ${regions}; do
        local content
        content=$(extract_region "${cli_file}" "${region}")
        echo "      ${region}:" >> "${tmp_file}"
        echo "        content: |" >> "${tmp_file}"
        echo "${content}" | sed 's/^/          /' >> "${tmp_file}"
      done
    fi

    # SDK
    if [ -n "${section_sdk[${section}]+x}" ]; then
      IFS='|' read -r sdk_file sdk_rel sdk_basename <<< "${section_sdk[${section}]}"
      local sdk_lang
      sdk_lang=$(detect_lang "${sdk_basename}")

      echo "  sdk:" >> "${tmp_file}"
      echo "    lang: \"${sdk_lang}\"" >> "${tmp_file}"
      echo "    filename: \"${sdk_basename}\"" >> "${tmp_file}"
      echo "    source_url: \"${GITHUB_BASE}/${sdk_rel}\"" >> "${tmp_file}"
      echo "    excerpts:" >> "${tmp_file}"

      local regions
      regions=$(list_regions "${sdk_file}")
      for region in ${regions}; do
        local content
        content=$(extract_region "${sdk_file}" "${region}")
        echo "      ${region}:" >> "${tmp_file}"
        echo "        content: |" >> "${tmp_file}"
        echo "${content}" | sed 's/^/          /' >> "${tmp_file}"
      done
    fi

    # DB
    if [ -n "${section_db[${section}]+x}" ]; then
      IFS='|' read -r db_file db_rel db_basename <<< "${section_db[${section}]}"
      local db_lang
      db_lang=$(detect_lang "${db_basename}")

      echo "  db:" >> "${tmp_file}"
      echo "    lang: \"${db_lang}\"" >> "${tmp_file}"
      echo "    filename: \"${db_basename}\"" >> "${tmp_file}"
      echo "    source_url: \"${GITHUB_BASE}/${db_rel}\"" >> "${tmp_file}"
      echo "    excerpts:" >> "${tmp_file}"

      local regions
      regions=$(list_regions "${db_file}")
      for region in ${regions}; do
        local content
        content=$(extract_region "${db_file}" "${region}")
        echo "      ${region}:" >> "${tmp_file}"
        echo "        content: |" >> "${tmp_file}"
        echo "${content}" | sed 's/^/          /' >> "${tmp_file}"
      done
    fi

    # Sigma (array — multiple files possible)
    if [ -n "${section_sigma[${section}]+x}" ]; then
      echo "  sigma:" >> "${tmp_file}"

      while IFS= read -r sigma_entry; do
        [ -z "${sigma_entry}" ] && continue
        IFS='|' read -r sigma_file sigma_rel sigma_basename <<< "${sigma_entry}"
        local sigma_lang
        sigma_lang=$(detect_lang "${sigma_basename}")

        echo "    - lang: \"${sigma_lang}\"" >> "${tmp_file}"
        echo "      filename: \"${sigma_basename}\"" >> "${tmp_file}"
        echo "      source_url: \"${GITHUB_BASE}/${sigma_rel}\"" >> "${tmp_file}"
        echo "      excerpts:" >> "${tmp_file}"

        local regions
        regions=$(list_regions "${sigma_file}")
        for region in ${regions}; do
          local content
          content=$(extract_region "${sigma_file}" "${region}")
          echo "        ${region}:" >> "${tmp_file}"
          echo "          content: |" >> "${tmp_file}"
          echo "${content}" | sed 's/^/            /' >> "${tmp_file}"
        done
      done <<< "${section_sigma[${section}]}"
    fi

    echo "" >> "${tmp_file}"
  done

  local section_count=0
  [ ${#sections_seen[@]} -gt 0 ] 2>/dev/null && section_count=${#sections_seen[@]}
  local file_count=${#marked_files[@]}

  # Validate YAML before copying to destination (catches corruption early)
  if command -v python3 &>/dev/null; then
    if ! python3 -c "import yaml; yaml.safe_load(open('${tmp_file}'))" 2>/dev/null; then
      echo "  ✗ ${vendor}: YAML validation FAILED — skipping (see ${tmp_file})" >&2
      return 1
    fi
  fi

  # Atomic copy from native-fs temp to NTFS destination
  cp "${tmp_file}" "${output_file}"
  echo "  ✓ ${vendor}: ${file_count} files → ${section_count} sections → ${output_file}"
}

echo "═══ HTH Pack → Jekyll Data Sync ═══"
echo ""

# Process each vendor directory
for vendor_dir in "${PACKS_DIR}"/*/; do
  vendor=$(basename "${vendor_dir}")
  # Only process vendors that have code files (not just control YAMLs)
  if ls "${vendor_dir}"/terraform/hth-*.tf 2>/dev/null | head -1 > /dev/null 2>&1 || \
     ls "${vendor_dir}"/api/hth-*.sh 2>/dev/null | head -1 > /dev/null 2>&1 || \
     ls "${vendor_dir}"/cli/hth-*.sh 2>/dev/null | head -1 > /dev/null 2>&1 || \
     ls "${vendor_dir}"/sdk/hth-*.* 2>/dev/null | head -1 > /dev/null 2>&1 || \
     ls "${vendor_dir}"/db/hth-*.* 2>/dev/null | head -1 > /dev/null 2>&1 || \
     ls "${vendor_dir}"/siem/sigma/hth-*.yml 2>/dev/null | head -1 > /dev/null 2>&1; then
    process_vendor "${vendor}"
  fi
done

echo ""
echo "Done. Run 'cd docs && bundle exec jekyll serve' to preview."
